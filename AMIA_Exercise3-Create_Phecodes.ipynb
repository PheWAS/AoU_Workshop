{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Create Phecodes and Demographics\n",
    "\n",
    "This notebook will extract ICD9CM and ICD10CM codes from the CDR. It will then transform those codes into phecodes for analysis. It also creates a basic demographics table.\n",
    "\n",
    "I used a Standard VM with 16 CPUs and 104GB RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install PheWAS Package\n",
    "\n",
    "First, we will install the PheWAS package. The kernel may require a restart after this. Fortunately, this install should stay with our persistent disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if(!require(PheWAS)) devtools::install_github(\"PheWAS/PheWAS\", upgrade=FALSE)\n",
    "library(PheWAS)\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup bigrquery\n",
    "\n",
    "This is a convenience function we can use to query the default CDR for this workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(bigrquery)  # BigQuery R client.\n",
    "\n",
    "## BigQuery setup.\n",
    "BILLING_PROJECT_ID <- Sys.getenv('GOOGLE_PROJECT')\n",
    "# Get the BigQuery curated dataset for the current workspace context.\n",
    "CDR <- Sys.getenv('WORKSPACE_CDR')\n",
    "# Bucket\n",
    "WORKSPACE_BUCKET <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "#Query\n",
    "bq <- function(query) {bq_table_download(bq_project_query(\n",
    "    BILLING_PROJECT_ID, page_size = 25000,\n",
    "    query=query, default_dataset = CDR ))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Python bigquery\n",
    "\n",
    "We will additionally use the python bigquery library with the reticulate package. It supports querying GCS files as BQ tables, which we can leverage to map phecodes in BQ instead of locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(reticulate)\n",
    "bigquery=import(\"google.cloud.bigquery\")\n",
    "\n",
    "client = bigquery$Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save phecode map\n",
    "\n",
    "We first export the phecode map from the PheWAS Package and save it to our workspace bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the phecode map\n",
    "expanded_phecode = inner_join(PheWAS::phecode_map, rename(PheWAS::phecode_rollup_map, phecode=code)) %>% transmute(vocabulary_id, concept_code=code, phecode=phecode_unrolled)\n",
    "write_csv(expanded_phecode, file=\"expanded_phecode.csv\")\n",
    "system2(\"gsutil\",args = c(\"cp\",\"expanded_phecode.csv\",WORKSPACE_BUCKET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the phecode map table for BQ\n",
    "\n",
    "We are adding our GCS phecode table as an external table for BQ. This provides the metadata BQ needs to interpret the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phecode = bigquery$ExternalConfig('CSV')\n",
    "phecode$source_uris = c(sprintf(\"%s/expanded_phecode.csv\",WORKSPACE_BUCKET))\n",
    "phecode$schema = c(\n",
    "    bigquery$SchemaField('vocabulary_id', 'STRING'),\n",
    "    bigquery$SchemaField('concept_code', 'STRING'),\n",
    "    bigquery$SchemaField('phecode', 'STRING')\n",
    ")\n",
    "py_set_attr(phecode$options,\"skip_leading_rows\", \"1\")  # optionally skip header row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract phecodes\n",
    "\n",
    "We use BQ to select all ICD9CM and ICD10CM codes, map them to phecodes, and aggregate them by selecting unique counts of dates per phecode. The BQ configuration code includes the above definition of our external table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icds=sprintf(\"with all_codes as (select * from (\n",
    "select distinct person_id, vocabulary_id, concept_code, condition_start_date as date\n",
    "from condition_occurrence join concept on (condition_source_concept_id=concept_id)\n",
    "where vocabulary_id in ('ICD9CM','ICD10CM')\n",
    "union distinct\n",
    "select distinct person_id, vocabulary_id, concept_code, observation_date as date\n",
    "from observation join concept on (observation_source_concept_id=concept_id)\n",
    "where vocabulary_id in ('ICD9CM','ICD10CM')\n",
    "union distinct\n",
    "select distinct person_id, vocabulary_id, concept_code, procedure_date as date\n",
    "from procedure_occurrence join concept on (procedure_source_concept_id=concept_id)\n",
    "where vocabulary_id in ('ICD9CM','ICD10CM')\n",
    "union distinct\n",
    "select distinct person_id, vocabulary_id, concept_code, measurement_date as date\n",
    "from measurement join concept on (measurement_source_concept_id=concept_id)\n",
    "where vocabulary_id in ('ICD9CM','ICD10CM')\n",
    "))\n",
    "select person_id, phecode, count(distinct date) as count from\n",
    "all_codes join expanded_phecode using (vocabulary_id, concept_code)\n",
    "group by person_id, phecode\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config = bigquery$QueryJobConfig()\n",
    "job_config$table_definitions = c(\"expanded_phecode\" = phecode)\n",
    "job_config$default_dataset = CDR\n",
    "query_job = client$query(icds, job_config=job_config)  # API request\n",
    "\n",
    "data = query_job$to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract total population list\n",
    "\n",
    "It is possible that some healthy controls may not have any phecodes. We will find all individuals with any ICD9CM or ICD10CM billing codes to consider them the denominator. This should give us a reasonably consistent overall EHR population- true healthy controls should at least have well visit codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get individuals with EHR data (for control list)\n",
    "all_code_query=\"with all_codes as (select * from (\n",
    "select distinct person_id, src_id\n",
    "from condition_occurrence join condition_occurrence_ext using (condition_occurrence_id) join concept on (condition_source_concept_id=concept_id)\n",
    "where vocabulary_id in ('ICD9CM','ICD10CM') and src_id like 'EHR%'\n",
    "union distinct\n",
    "select distinct person_id, src_id\n",
    "from observation join observation_ext using (observation_id) join concept on (observation_source_concept_id=concept_id)\n",
    "where vocabulary_id in ('ICD9CM','ICD10CM') and src_id like 'EHR%'\n",
    "union distinct\n",
    "select distinct person_id, src_id\n",
    "from procedure_occurrence join procedure_occurrence_ext using (procedure_occurrence_id) join concept on (procedure_source_concept_id=concept_id)\n",
    "where vocabulary_id in ('ICD9CM','ICD10CM') and src_id like 'EHR%'\n",
    "union distinct\n",
    "select distinct person_id, src_id\n",
    "from measurement join measurement_ext using (measurement_id) join concept on (measurement_source_concept_id=concept_id)\n",
    "where vocabulary_id in ('ICD9CM','ICD10CM') and src_id like 'EHR%'\n",
    "))\n",
    "select distinct person_id, src_id from\n",
    "all_codes\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config = bigquery$QueryJobConfig()\n",
    "job_config$default_dataset = CDR\n",
    "query_job = client$query(all_code_query, job_config=job_config)  # API request\n",
    "\n",
    "ehr_inds = query_job$to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple EHR sites\n",
    "\n",
    "As a note, some individuals have data from multiple EHR sites, which is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_inds %>% group_by(person_id) %>% summarize(n_site=n()) %>% group_by(n_site) %>% summarize(n())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create distinct participant ID list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_person_ids= (ehr_inds %>% select(person_id) %>% distinct())[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sex covariates\n",
    "\n",
    "We next create a covariate of self reported sex at birth to exclude individuals from sex-specific phecodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config = bigquery$QueryJobConfig()\n",
    "job_config$default_dataset = CDR\n",
    "query_job = client$query(\"select person_id, \n",
    "case when sex_at_birth_concept_id=45878463 then 'F'\n",
    "when sex_at_birth_concept_id=45880669 then 'M'\n",
    "else '0'\n",
    "end as sex\n",
    "from person\", \n",
    "                         job_config=job_config)  # API request\n",
    "\n",
    "sex_info = query_job$to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(sex_info$sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Phenotypes\n",
    "\n",
    "Using the PheWAS Package, we will create our phecode table. This incorporates the already mapped phecodes, a minimum code count of 2, our sex exclusion list, and an overall population list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phe_table = createPhenotypes(data %>% transmute(person_id, vocabulary_id=\"phecode\",phecode, count), \n",
    "                             translate=FALSE, min.code.count=2, add.phecode.exclusions=FALSE,\n",
    "                             id.sex=sex_info,full.population.ids=ehr_person_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(phe_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the file\n",
    "\n",
    "Next, we save the file. We can also upload the file to our workspace bucket so we can retrieve it later. Note that this file is quite large, so will take some time to upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(phe_table,file=\"phecode_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally upload the file to your bucket for safe-keeping\n",
    "#system2(\"gsutil\",args = c(\"cp\",\"phecode_table.csv\",WORKSPACE_BUCKET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Demographics\n",
    "\n",
    "We will also create a small demographics table for use. This is based on the OMOP person table, which contains self-reported information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config = bigquery$QueryJobConfig()\n",
    "job_config$default_dataset = CDR\n",
    "query_job = client$query(\"select * from person\", \n",
    "                         job_config=job_config)  # API request\n",
    "\n",
    "demo_raw = query_job$to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the raw data if it's of interest!\n",
    "#head(demo_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_raw %>% group_by(ethnicity_source_value) %>% summarize(n())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplify the data for covariates\n",
    "\n",
    "Note that we will not use all of these covariates in our analysis- you may find them useful or not for your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo=demo_raw %>% transmute(person_id, \n",
    "                            age=2023-year_of_birth, \n",
    "                            race_w_nh=((race_source_value==\"WhatRaceEthnicity_White\")&(ethnicity_source_value==\"Not Hispanic\")),\n",
    "                            sex_ab_F=sex_at_birth_source_value==\"SexAtBirth_Female\",\n",
    "                           race_source_value, ethnicity_source_value, sex_at_birth_source_value, year_of_birth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the data as is\n",
    "#head(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View scrambled data\n",
    "demo %>% transmute(across(-person_id, \\(x) sample(x))) %>% head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo %>% group_by(race_w_nh) %>% summarize(n())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the file\n",
    "\n",
    "Write it to the local VM then save to the workspace bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(demo,file=\"demo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system2(\"gsutil\",args = c(\"cp\",\"demo.csv\",WORKSPACE_BUCKET))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
